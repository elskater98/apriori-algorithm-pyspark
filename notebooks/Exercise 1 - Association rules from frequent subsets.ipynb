{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7438a126",
   "metadata": {},
   "source": [
    "## Exercise A-Priori Algorithm\n",
    "\n",
    "Consider the following programming exercise. Given the information of the frequent singletons $(L_1)$ and frequent pairs $(L_2)$ we compute with our previous implementation of A-Priori for k=2, implement in spark functions to compute the  **confidence** and **interest** of all the binary rules we can build from the set $L_2$. As the dataset to test your code, use the one you can find in:\n",
    "\n",
    "https://www.kaggle.com/shazadudwadia/supermarket?select=GroceryStoreDataSet.csv\n",
    "\n",
    "Your algorithm should follow these steps:\n",
    "\n",
    "1. Map, using mapPartitions, each frequent pair in the RDD with L2 to its list of binary association rules (two association rules per each different frequent pair). Use then the flattened version of this RDD.\n",
    "2. Map each association rule of the previous resulting RDD, to a triple with (rule,confidence,interest). Observe that you will need to use the information in L1 and the number of transactions to compute these values. You can use the version of L1 stored as a python list in the driver (so it can be passed inside functions passed to spark tasks).\n",
    "3. Finally, sort the association rules by their interest, and show back in the driver program the first 10 most interesting rules\n",
    "\n",
    "Try your algorithm with at least these three values for the parameter theta: {  0.01, 0.1, 0.2 }\n",
    "\n",
    "\n",
    "Present your final notebook with all the needed code (the already provided A-priori algorithm plus your code for the association rules as requested) together with the results obtained with the different values of theta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6dd68",
   "metadata": {},
   "source": [
    "## High-level pseudo-code of the A-Priori algorithm\n",
    "\n",
    ">$L_1$ := Find frequent elements (T,$\\theta$)  \n",
    ">k=2  \n",
    ">While ($L_{k-1}$ is not empty) do:  \n",
    ">>$C_k = \\{ P \\ | \\ |P|=k, \\forall S_j \\subseteq P, |S_j|=k\\!-\\!1 \\rightarrow S_j \\in L_{k-1}\\}$  \n",
    ">>$L_k = \\{ P \\ | \\ P \\in C_k, support(P,T) \\geq \\theta \\}$  \n",
    ">>k=k+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Variables and constants\n",
    "K=2\n",
    "theta=0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a62a3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b560m.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>A-Priori Algorithm</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=A-Priori Algorithm>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init Spark Context\n",
    "sc = pyspark.SparkContext('local[*]','A-Priori Algorithm')\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40926394",
   "metadata": {},
   "source": [
    "**Phase 1:** Compute $L_1$ and $T_{L_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81829acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº Transactions: 20\n",
      "\n",
      "[['MILK', 'BREAD', 'BISCUIT'], ['BREAD', 'MILK', 'BISCUIT', 'CORNFLAKES'], ['BREAD', 'TEA', 'BOURNVITA'], ['JAM', 'MAGGI', 'BREAD', 'MILK'], ['MAGGI', 'TEA', 'BISCUIT'], ['BREAD', 'TEA', 'BOURNVITA'], ['MAGGI', 'TEA', 'CORNFLAKES'], ['MAGGI', 'BREAD', 'TEA', 'BISCUIT'], ['JAM', 'MAGGI', 'BREAD', 'TEA'], ['BREAD', 'MILK'], ['COFFEE', 'COCK', 'BISCUIT', 'CORNFLAKES'], ['COFFEE', 'COCK', 'BISCUIT', 'CORNFLAKES'], ['COFFEE', 'SUGER', 'BOURNVITA'], ['BREAD', 'COFFEE', 'COCK'], ['BREAD', 'SUGER', 'BISCUIT'], ['COFFEE', 'SUGER', 'CORNFLAKES'], ['BREAD', 'SUGER', 'BOURNVITA'], ['BREAD', 'COFFEE', 'SUGER'], ['BREAD', 'COFFEE', 'SUGER'], ['TEA', 'MILK', 'COFFEE', 'CORNFLAKES']]\n"
     ]
    }
   ],
   "source": [
    "# Read CSV and parse\n",
    "transactions = sc.textFile(\"GroceryStoreDataSet.csv\").map(lambda line: line.strip().replace(\"\\\"\",'').split(\",\"))\n",
    "number_transactions = transactions.count()\n",
    "print(\"NÂº Transactions: %s\\n\\n%s\" % (number_transactions,transactions.collect()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501c9846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MILK', 5), ('BREAD', 13), ('BISCUIT', 7), ('CORNFLAKES', 6), ('TEA', 7), ('MAGGI', 5), ('COFFEE', 8), ('SUGER', 6), ('BOURNVITA', 4)]\n"
     ]
    }
   ],
   "source": [
    "# Compute the rdd with frequent singleton sets (L_1)\n",
    "def computeL1 ( rddT, numtrans, theta ):\n",
    "  rddtemp = rddT.flatMap( lambda t : [ (it,1) for it in t ] ).reduceByKey( lambda a,b : a+b  )\n",
    "  return rddtemp.filter( lambda x : (float(x[1])/numtrans) >= theta )\n",
    "\n",
    "aux_L1 = computeL1(transactions,number_transactions,theta)\n",
    "print(aux_L1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1cd44da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Items: ['MILK', 'BREAD', 'BISCUIT', 'CORNFLAKES', 'TEA', 'MAGGI', 'COFFEE', 'SUGER', 'BOURNVITA']\n"
     ]
    }
   ],
   "source": [
    "L1 = aux_L1.keys().collect()\n",
    "print(\"L1 Items: %s\"% L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b19f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions with only frequent elements [['MILK', 'BREAD', 'BISCUIT'], ['BREAD', 'MILK', 'BISCUIT', 'CORNFLAKES'], ['BREAD', 'TEA', 'BOURNVITA'], ['MAGGI', 'BREAD', 'MILK'], ['MAGGI', 'TEA', 'BISCUIT'], ['BREAD', 'TEA', 'BOURNVITA'], ['MAGGI', 'TEA', 'CORNFLAKES'], ['MAGGI', 'BREAD', 'TEA', 'BISCUIT'], ['MAGGI', 'BREAD', 'TEA'], ['BREAD', 'MILK'], ['COFFEE', 'BISCUIT', 'CORNFLAKES'], ['COFFEE', 'BISCUIT', 'CORNFLAKES'], ['COFFEE', 'SUGER', 'BOURNVITA'], ['BREAD', 'COFFEE'], ['BREAD', 'SUGER', 'BISCUIT'], ['COFFEE', 'SUGER', 'CORNFLAKES'], ['BREAD', 'SUGER', 'BOURNVITA'], ['BREAD', 'COFFEE', 'SUGER'], ['BREAD', 'COFFEE', 'SUGER'], ['TEA', 'MILK', 'COFFEE', 'CORNFLAKES']]\n"
     ]
    }
   ],
   "source": [
    "# Map any transaction to its version without elements not in L1\n",
    "# L1 must be a python list, not a RDD\n",
    "def computeTfilteredByL1( seqOfT, L1 ):\n",
    "    for t in seqOfT:\n",
    "       yield [ it for it in t if (it in L1) ]\n",
    "    \n",
    "TL1 = transactions.mapPartitions( lambda seqOfT : computeTfilteredByL1( seqOfT, L1 ))\n",
    "print(\"Transactions with only frequent elements %s\" % TL1.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1edbb",
   "metadata": {},
   "source": [
    " **Phase 2:** Compute $C_2(T)$ from $T_{L_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbf8cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each t in seqofFilteredT (they come from T_{L_1}), compute pairs (a,b) from t that belong to C_2\n",
    "def generateC2( seqofFilteredT ):\n",
    "    for t in seqofFilteredT:\n",
    "      cpairslist = []\n",
    "      for (a,b) in [ (a,b) for i,a in enumerate(t[:-1]) for b in t[i+1:] ]:\n",
    "                cpairslist.append( ((a,b),1) if (a <= b) else ((b,a),1)  )         \n",
    "      yield cpairslist\n",
    "    \n",
    "rddC2T = TL1.mapPartitions( lambda seqOfFilteredT : generateC2( seqOfFilteredT ) )\n",
    "rddC2TFlat = rddC2T.flatMap( lambda x : x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f224f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened C2T:  [(('BREAD', 'MILK'), 1), (('BISCUIT', 'MILK'), 1), (('BISCUIT', 'BREAD'), 1), (('BREAD', 'MILK'), 1), (('BISCUIT', 'BREAD'), 1), (('BREAD', 'CORNFLAKES'), 1), (('BISCUIT', 'MILK'), 1), (('CORNFLAKES', 'MILK'), 1), (('BISCUIT', 'CORNFLAKES'), 1), (('BREAD', 'TEA'), 1), (('BOURNVITA', 'BREAD'), 1), (('BOURNVITA', 'TEA'), 1), (('BREAD', 'MAGGI'), 1), (('MAGGI', 'MILK'), 1), (('BREAD', 'MILK'), 1), (('MAGGI', 'TEA'), 1), (('BISCUIT', 'MAGGI'), 1), (('BISCUIT', 'TEA'), 1), (('BREAD', 'TEA'), 1), (('BOURNVITA', 'BREAD'), 1), (('BOURNVITA', 'TEA'), 1), (('MAGGI', 'TEA'), 1), (('CORNFLAKES', 'MAGGI'), 1), (('CORNFLAKES', 'TEA'), 1), (('BREAD', 'MAGGI'), 1), (('MAGGI', 'TEA'), 1), (('BISCUIT', 'MAGGI'), 1), (('BREAD', 'TEA'), 1), (('BISCUIT', 'BREAD'), 1), (('BISCUIT', 'TEA'), 1), (('BREAD', 'MAGGI'), 1), (('MAGGI', 'TEA'), 1), (('BREAD', 'TEA'), 1), (('BREAD', 'MILK'), 1), (('BISCUIT', 'COFFEE'), 1), (('COFFEE', 'CORNFLAKES'), 1), (('BISCUIT', 'CORNFLAKES'), 1), (('BISCUIT', 'COFFEE'), 1), (('COFFEE', 'CORNFLAKES'), 1), (('BISCUIT', 'CORNFLAKES'), 1), (('COFFEE', 'SUGER'), 1), (('BOURNVITA', 'COFFEE'), 1), (('BOURNVITA', 'SUGER'), 1), (('BREAD', 'COFFEE'), 1), (('BREAD', 'SUGER'), 1), (('BISCUIT', 'BREAD'), 1), (('BISCUIT', 'SUGER'), 1), (('COFFEE', 'SUGER'), 1), (('COFFEE', 'CORNFLAKES'), 1), (('CORNFLAKES', 'SUGER'), 1), (('BREAD', 'SUGER'), 1), (('BOURNVITA', 'BREAD'), 1), (('BOURNVITA', 'SUGER'), 1), (('BREAD', 'COFFEE'), 1), (('BREAD', 'SUGER'), 1), (('COFFEE', 'SUGER'), 1), (('BREAD', 'COFFEE'), 1), (('BREAD', 'SUGER'), 1), (('COFFEE', 'SUGER'), 1), (('MILK', 'TEA'), 1), (('COFFEE', 'TEA'), 1), (('CORNFLAKES', 'TEA'), 1), (('COFFEE', 'MILK'), 1), (('CORNFLAKES', 'MILK'), 1), (('COFFEE', 'CORNFLAKES'), 1)] Count:  65\n"
     ]
    }
   ],
   "source": [
    "print( \"flattened C2T: \", rddC2TFlat.collect(), \"Count: \",rddC2TFlat.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c01ae",
   "metadata": {},
   "source": [
    "**Phase 3:** Compute ð¿2 from ð¶2(ð‘‡)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3c2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeL2( rddC2T, numtrans, theta ):\n",
    "    pairsCountedrdd = rddC2T.reduceByKey( lambda v1,v2 : v1+v2 )\n",
    "    # print(pairsCountedrdd.collect())\n",
    "    # Finally, filter out from the previous rdd those pairs with frequency below theta\n",
    "    return pairsCountedrdd.filter( lambda x : (float(x[1])/numtrans) >= theta )\n",
    "\n",
    "rddL2 = computeL2( rddC2TFlat, number_transactions, theta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d9a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('BREAD', 'MILK'), 4)\n",
      "(('BISCUIT', 'BREAD'), 4)\n",
      "(('BREAD', 'TEA'), 4)\n",
      "(('MAGGI', 'TEA'), 4)\n",
      "(('COFFEE', 'CORNFLAKES'), 4)\n",
      "(('COFFEE', 'SUGER'), 4)\n",
      "(('BREAD', 'SUGER'), 4)\n"
     ]
    }
   ],
   "source": [
    "rddL2 = rddL2.sortBy(lambda a: -a[1])\n",
    "for it in rddL2.toLocalIterator():\n",
    "    print (it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431128e",
   "metadata": {},
   "source": [
    "### Confidence\n",
    "\n",
    "$$ \\frac{support( {diapers,beer} )}{support( {diapers})} $$\n",
    "where support(set) is the number of transactions where the set is found.\n",
    "\n",
    "### Interest\n",
    "\n",
    "$$ interest = confidence ( {diapers} \\rightarrow {beer} ) - frequency( {beer} ) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed80cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(partitionData,L1):\n",
    "    for element in partitionData:                                           \n",
    "        yield (element[0], round(element[1] / L1[element[0][0]],2))\n",
    "        \n",
    "def interest(confidence, freq):\n",
    "    return round(confidence - freq,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a81458bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('BREAD', 'MILK'), 0.31), (('BISCUIT', 'BREAD'), 0.57), (('BREAD', 'TEA'), 0.31), (('MAGGI', 'TEA'), 0.8), (('COFFEE', 'CORNFLAKES'), 0.5), (('COFFEE', 'SUGER'), 0.5), (('BREAD', 'SUGER'), 0.31), (('MILK', 'BREAD'), 0.8), (('BREAD', 'BISCUIT'), 0.31), (('TEA', 'BREAD'), 0.57), (('TEA', 'MAGGI'), 0.57), (('CORNFLAKES', 'COFFEE'), 0.67), (('SUGER', 'COFFEE'), 0.67), (('SUGER', 'BREAD'), 0.67)]\n"
     ]
    }
   ],
   "source": [
    "L1_dict = dict((key, value) for key, value in aux_L1.collect())\n",
    "\n",
    "inverseL2 = rddL2.map(lambda i: ((i[0][1],i[0][0]),i[1]))\n",
    "\n",
    "all_rules = rddL2.union(inverseL2)\n",
    "\n",
    "confidenceRDD = all_rules.mapPartitions(lambda i: confidence(i,L1_dict))\n",
    "print(confidenceRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c80bc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules(partitionData, L1, ntransaction):\n",
    "    for confidence in partitionData:\n",
    "        rule = str(confidence[0]).replace(',','->').replace('\\'','')[1:-1]\n",
    "        _confidence = confidence[1]\n",
    "        _interest = interest(confidence[1], L1[confidence[0][1]]/ntransaction)\n",
    "        yield (rule,_confidence,_interest)\n",
    "\n",
    "interestRDD = confidenceRDD.mapPartitions(lambda partitionData: rules(partitionData,L1_dict,number_transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b76fde37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MAGGI-> TEA', 0.8, 0.45),\n",
       " ('TEA-> MAGGI', 0.57, 0.32),\n",
       " ('CORNFLAKES-> COFFEE', 0.67, 0.27),\n",
       " ('SUGER-> COFFEE', 0.67, 0.27),\n",
       " ('COFFEE-> CORNFLAKES', 0.5, 0.2),\n",
       " ('COFFEE-> SUGER', 0.5, 0.2),\n",
       " ('MILK-> BREAD', 0.8, 0.15),\n",
       " ('BREAD-> MILK', 0.31, 0.06),\n",
       " ('SUGER-> BREAD', 0.67, 0.02),\n",
       " ('BREAD-> SUGER', 0.31, 0.01)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interestRDD.sortBy(lambda a: -a[2]).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c20560",
   "metadata": {},
   "source": [
    "## Results obtained with the different values of theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "038af7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_method(theta):\n",
    "    transactions = sc.textFile(\"GroceryStoreDataSet.csv\").map(lambda line: line.strip().replace(\"\\\"\",'').split(\",\"))\n",
    "    number_transactions = transactions.count()\n",
    "    \n",
    "    aux_L1 = computeL1(transactions,number_transactions,theta)\n",
    "    L1_dict = dict((key, value) for key, value in aux_L1.collect())\n",
    "    L1 = aux_L1.keys().collect()\n",
    "    TL1 = transactions.mapPartitions( lambda seqOfT : computeTfilteredByL1( seqOfT, L1 ))\n",
    "    \n",
    "    rddC2T = TL1.mapPartitions( lambda seqOfFilteredT : generateC2( seqOfFilteredT ) )\n",
    "    rddC2TFlat = rddC2T.flatMap( lambda x : x )\n",
    "    rddL2 = computeL2( rddC2TFlat, number_transactions, theta )\n",
    "    rddL2 = rddL2.sortBy(lambda a: -a[1])\n",
    "    \n",
    "    inverseL2 = rddL2.map(lambda i: ((i[0][1],i[0][0]),i[1]))\n",
    "    all_rules = rddL2.union(inverseL2)\n",
    "    \n",
    "    confidenceRDD = all_rules.mapPartitions(lambda i: confidence(i,L1_dict))\n",
    "    interestRDD = confidenceRDD.mapPartitions(lambda partitionData: rules(partitionData,L1_dict,number_transactions))\n",
    "    print(\"Theta: %s - NÂº Rules: %s\" % (theta,interestRDD.count()))\n",
    "    return interestRDD.sortBy(lambda a: -a[2]).take(10)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bbb346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: 0.21 - NÂº Rules: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_method(0.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11a50585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: 0.2 - NÂº Rules: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('MAGGI-> TEA', 0.8, 0.45),\n",
       " ('TEA-> MAGGI', 0.57, 0.32),\n",
       " ('CORNFLAKES-> COFFEE', 0.67, 0.27),\n",
       " ('SUGER-> COFFEE', 0.67, 0.27),\n",
       " ('COFFEE-> CORNFLAKES', 0.5, 0.2),\n",
       " ('COFFEE-> SUGER', 0.5, 0.2),\n",
       " ('MILK-> BREAD', 0.8, 0.15),\n",
       " ('BREAD-> MILK', 0.31, 0.06),\n",
       " ('SUGER-> BREAD', 0.67, 0.02),\n",
       " ('BREAD-> SUGER', 0.31, 0.01)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_method(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98d524f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: 0.1 - NÂº Rules: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('JAM-> MAGGI', 1.0, 0.75),\n",
       " ('COCK-> COFFEE', 1.0, 0.6),\n",
       " ('MAGGI-> TEA', 0.8, 0.45),\n",
       " ('COCK-> CORNFLAKES', 0.67, 0.37),\n",
       " ('JAM-> BREAD', 1.0, 0.35),\n",
       " ('TEA-> MAGGI', 0.57, 0.32),\n",
       " ('COCK-> BISCUIT', 0.67, 0.32),\n",
       " ('MAGGI-> JAM', 0.4, 0.3),\n",
       " ('CORNFLAKES-> COFFEE', 0.67, 0.27),\n",
       " ('SUGER-> COFFEE', 0.67, 0.27)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_method(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc29aa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: 0.01 - NÂº Rules: 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('JAM-> MAGGI', 1.0, 0.75),\n",
       " ('COCK-> COFFEE', 1.0, 0.6),\n",
       " ('MAGGI-> TEA', 0.8, 0.45),\n",
       " ('COCK-> CORNFLAKES', 0.67, 0.37),\n",
       " ('JAM-> BREAD', 1.0, 0.35),\n",
       " ('TEA-> MAGGI', 0.57, 0.32),\n",
       " ('COCK-> BISCUIT', 0.67, 0.32),\n",
       " ('MAGGI-> JAM', 0.4, 0.3),\n",
       " ('CORNFLAKES-> COFFEE', 0.67, 0.27),\n",
       " ('SUGER-> COFFEE', 0.67, 0.27)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_method(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae44f4",
   "metadata": {},
   "source": [
    "### Theta\n",
    "\n",
    "*Theta*, is a well-called thereshold or filter barrier. As we can see in the results, when we use **theta > 0.2**, we do not get rules because it determines the **low-pass-filter** value of support that at least appears in the transactions.\n",
    "\n",
    "In other words, *theta* filters by specifying how popular an itemset is, as measured by the proportion of transactions in which an itemset appears.\n",
    "\n",
    "Then we can say that when *theta* takes a smaller number, the number of rules increases, as the threshold filter is more permessive. In this way, we are able to analyse the trades and get more rules from the transactions.\n",
    "\n",
    "Another case come when using **theta as 0.01**, the number of rules that satisfy this condition is **72**, but when we apply **theta as 0.1**, this number decreases because the frequency rules filter is more stricted as *theta* takes higher values.\n",
    "\n",
    "### Confidence\n",
    "\n",
    "Regarding the confidence term, refers to how likely item *Y* is purchased when item *X* has been purchased, expressed as *(X -> Y)*\n",
    "\n",
    "So, confidence is measured by the proportion of transactions including item X, in which item Y also appears. But, in this part, *theta* does not take any consideration because the rules have been already generated.\n",
    "\n",
    "For example, the rule *'JAM'->'MAGGI'* has 100% of confidence. This rule has the probability of 100% meaning when JAM is purchased, for sure, Maggi will be.\n",
    "\n",
    "### Interest\n",
    "\n",
    "Interest helps to get a better real point of view according to confidence obtained, as confidence is a biased point of view because the dataset used.\n",
    "\n",
    "Observe that the interest can be positive, negative, or zero:\n",
    "\n",
    "- A positive interest indicates a positive effect, i.e. that when {I} is present {j} is more likely to be present than in general.\n",
    "\n",
    "- A negative interest indicates a negative effect, i.e. that when {I} is present {j} is less likely to be present than in general.\n",
    "\n",
    "- A zero interest indicates no significative effect of {I} to {j}: {I} being present does not affect the frequency of {j}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
