{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7438a126",
   "metadata": {},
   "source": [
    "## Exercise A-Priori Algorithm\n",
    "\n",
    "Consider the following programming exercise. Given the information of the frequent singletons $(L_1)$ and frequent pairs $(L_2)$ we compute with our previous implementation of A-Priori for k=2, implement in spark functions to compute the  **confidence** and **interest** of all the binary rules we can build from the set $L_2$. As the dataset to test your code, use the one you can find in:\n",
    "\n",
    "https://www.kaggle.com/shazadudwadia/supermarket?select=GroceryStoreDataSet.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6dd68",
   "metadata": {},
   "source": [
    "## High-level pseudo-code of the A-Priori algorithm\n",
    "\n",
    ">$L_1$ := Find frequent elements (T,$\\theta$)  \n",
    ">k=2  \n",
    ">While ($L_{k-1}$ is not empty) do:  \n",
    ">>$C_k = \\{ P \\ | \\ |P|=k, \\forall S_j \\subseteq P, |S_j|=k\\!-\\!1 \\rightarrow S_j \\in L_{k-1}\\}$  \n",
    ">>$L_k = \\{ P \\ | \\ P \\in C_k, support(P,T) \\geq \\theta \\}$  \n",
    ">>k=k+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Variables and constants\n",
    "K=2\n",
    "theta=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a62a3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b560m.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>A-Priori Algorithm</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=A-Priori Algorithm>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init Spark Context\n",
    "sc = pyspark.SparkContext('local[*]','A-Priori Algorithm')\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40926394",
   "metadata": {},
   "source": [
    "### Phase 1: Compute $L_1$ and $T_{L_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81829acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº Transactions: 20\n",
      "\n",
      "[['MILK', 'BREAD', 'BISCUIT'], ['BREAD', 'MILK', 'BISCUIT', 'CORNFLAKES'], ['BREAD', 'TEA', 'BOURNVITA'], ['JAM', 'MAGGI', 'BREAD', 'MILK'], ['MAGGI', 'TEA', 'BISCUIT'], ['BREAD', 'TEA', 'BOURNVITA'], ['MAGGI', 'TEA', 'CORNFLAKES'], ['MAGGI', 'BREAD', 'TEA', 'BISCUIT'], ['JAM', 'MAGGI', 'BREAD', 'TEA'], ['BREAD', 'MILK'], ['COFFEE', 'COCK', 'BISCUIT', 'CORNFLAKES'], ['COFFEE', 'COCK', 'BISCUIT', 'CORNFLAKES'], ['COFFEE', 'SUGER', 'BOURNVITA'], ['BREAD', 'COFFEE', 'COCK'], ['BREAD', 'SUGER', 'BISCUIT'], ['COFFEE', 'SUGER', 'CORNFLAKES'], ['BREAD', 'SUGER', 'BOURNVITA'], ['BREAD', 'COFFEE', 'SUGER'], ['BREAD', 'COFFEE', 'SUGER'], ['TEA', 'MILK', 'COFFEE', 'CORNFLAKES']]\n"
     ]
    }
   ],
   "source": [
    "# Read CSV and parse\n",
    "transactions = sc.textFile(\"../data/GroceryStoreDataSet.csv\").map(lambda line: line.replace(\"\\\"\",'').split(\",\"))\n",
    "number_transactions = transactions.count()\n",
    "print(\"Nº Transactions: %s\\n\\n%s\" % (number_transactions,transactions.collect()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501c9846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MILK', 5), ('BREAD', 13), ('BISCUIT', 7), ('CORNFLAKES', 6), ('TEA', 7), ('MAGGI', 5), ('COFFEE', 8), ('COCK', 3), ('SUGER', 6), ('BOURNVITA', 4), ('JAM', 2)]\n",
      "L1 Items: ['MILK', 'BREAD', 'BISCUIT', 'CORNFLAKES', 'TEA', 'MAGGI', 'COFFEE', 'COCK', 'SUGER', 'BOURNVITA', 'JAM']\n"
     ]
    }
   ],
   "source": [
    "# Compute the rdd with frequent singleton sets (L_1)\n",
    "def computeL1 ( rddT, numtrans, theta ):\n",
    "  rddtemp = rddT.flatMap( lambda t : [ (it,1) for it in t ] ).reduceByKey( lambda a,b : a+b  )\n",
    "  return rddtemp.filter( lambda x : (float(x[1])/numtrans) >= theta )\n",
    "\n",
    "aux_L1 = computeL1(transactions,number_transactions,theta)\n",
    "print(aux_L1.collect())\n",
    "\n",
    "L1 = aux_L1.keys().collect()\n",
    "print(\"L1 Items: %s\"% L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b19f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions with only frequent elements [['MILK', 'BREAD', 'BISCUIT'], ['BREAD', 'MILK', 'BISCUIT', 'CORNFLAKES'], ['BREAD', 'TEA', 'BOURNVITA'], ['JAM', 'MAGGI', 'BREAD', 'MILK'], ['MAGGI', 'TEA', 'BISCUIT'], ['BREAD', 'TEA', 'BOURNVITA'], ['MAGGI', 'TEA', 'CORNFLAKES'], ['MAGGI', 'BREAD', 'TEA', 'BISCUIT'], ['JAM', 'MAGGI', 'BREAD', 'TEA'], ['BREAD', 'MILK'], ['COFFEE', 'COCK', 'BISCUIT', 'CORNFLAKES'], ['COFFEE', 'COCK', 'BISCUIT', 'CORNFLAKES'], ['COFFEE', 'SUGER', 'BOURNVITA'], ['BREAD', 'COFFEE', 'COCK'], ['BREAD', 'SUGER', 'BISCUIT'], ['COFFEE', 'SUGER', 'CORNFLAKES'], ['BREAD', 'SUGER', 'BOURNVITA'], ['BREAD', 'COFFEE', 'SUGER'], ['BREAD', 'COFFEE', 'SUGER'], ['TEA', 'MILK', 'COFFEE', 'CORNFLAKES']]\n"
     ]
    }
   ],
   "source": [
    "# Map any transaction to its version without elements not in L1\n",
    "# L1 must be a python list, not a RDD\n",
    "def computeTfilteredByL1( seqOfT, L1 ):\n",
    "    for t in seqOfT:\n",
    "       yield [ it for it in t if (it in L1) ]\n",
    "    \n",
    "TL1 = transactions.mapPartitions( lambda seqOfT : computeTfilteredByL1( seqOfT, L1 ))\n",
    "print(\"Transactions with only frequent elements %s\" % TL1.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1edbb",
   "metadata": {},
   "source": [
    "### **Phase 2**: Compute $C_2(T)$ from $T_{L_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf8cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each t in seqofFilteredT (they come from T_{L_1}), compute pairs (a,b) from t that belong to C_2\n",
    "def generateC2( seqofFilteredT ):\n",
    "    for t in seqofFilteredT:\n",
    "      cpairslist = []\n",
    "      for (a,b) in [ (a,b) for i,a in enumerate(t[:-1]) for b in t[i+1:] ]:\n",
    "                cpairslist.append( ((a,b),1) if (a <= b) else ((b,a),1)  )         \n",
    "      yield cpairslist\n",
    "    \n",
    "rddC2T = TL1.mapPartitions( lambda seqOfFilteredT : generateC2( seqOfFilteredT ) )\n",
    "rddC2TFlat = rddC2T.flatMap( lambda x : x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f224f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened C2T:  [(('BREAD', 'MILK'), 1), (('BISCUIT', 'MILK'), 1), (('BISCUIT', 'BREAD'), 1), (('BREAD', 'MILK'), 1), (('BISCUIT', 'BREAD'), 1), (('BREAD', 'CORNFLAKES'), 1), (('BISCUIT', 'MILK'), 1), (('CORNFLAKES', 'MILK'), 1), (('BISCUIT', 'CORNFLAKES'), 1), (('BREAD', 'TEA'), 1), (('BOURNVITA', 'BREAD'), 1), (('BOURNVITA', 'TEA'), 1), (('JAM', 'MAGGI'), 1), (('BREAD', 'JAM'), 1), (('JAM', 'MILK'), 1), (('BREAD', 'MAGGI'), 1), (('MAGGI', 'MILK'), 1), (('BREAD', 'MILK'), 1), (('MAGGI', 'TEA'), 1), (('BISCUIT', 'MAGGI'), 1), (('BISCUIT', 'TEA'), 1), (('BREAD', 'TEA'), 1), (('BOURNVITA', 'BREAD'), 1), (('BOURNVITA', 'TEA'), 1), (('MAGGI', 'TEA'), 1), (('CORNFLAKES', 'MAGGI'), 1), (('CORNFLAKES', 'TEA'), 1), (('BREAD', 'MAGGI'), 1), (('MAGGI', 'TEA'), 1), (('BISCUIT', 'MAGGI'), 1), (('BREAD', 'TEA'), 1), (('BISCUIT', 'BREAD'), 1), (('BISCUIT', 'TEA'), 1), (('JAM', 'MAGGI'), 1), (('BREAD', 'JAM'), 1), (('JAM', 'TEA'), 1), (('BREAD', 'MAGGI'), 1), (('MAGGI', 'TEA'), 1), (('BREAD', 'TEA'), 1), (('BREAD', 'MILK'), 1), (('COCK', 'COFFEE'), 1), (('BISCUIT', 'COFFEE'), 1), (('COFFEE', 'CORNFLAKES'), 1), (('BISCUIT', 'COCK'), 1), (('COCK', 'CORNFLAKES'), 1), (('BISCUIT', 'CORNFLAKES'), 1), (('COCK', 'COFFEE'), 1), (('BISCUIT', 'COFFEE'), 1), (('COFFEE', 'CORNFLAKES'), 1), (('BISCUIT', 'COCK'), 1), (('COCK', 'CORNFLAKES'), 1), (('BISCUIT', 'CORNFLAKES'), 1), (('COFFEE', 'SUGER'), 1), (('BOURNVITA', 'COFFEE'), 1), (('BOURNVITA', 'SUGER'), 1), (('BREAD', 'COFFEE'), 1), (('BREAD', 'COCK'), 1), (('COCK', 'COFFEE'), 1), (('BREAD', 'SUGER'), 1), (('BISCUIT', 'BREAD'), 1), (('BISCUIT', 'SUGER'), 1), (('COFFEE', 'SUGER'), 1), (('COFFEE', 'CORNFLAKES'), 1), (('CORNFLAKES', 'SUGER'), 1), (('BREAD', 'SUGER'), 1), (('BOURNVITA', 'BREAD'), 1), (('BOURNVITA', 'SUGER'), 1), (('BREAD', 'COFFEE'), 1), (('BREAD', 'SUGER'), 1), (('COFFEE', 'SUGER'), 1), (('BREAD', 'COFFEE'), 1), (('BREAD', 'SUGER'), 1), (('COFFEE', 'SUGER'), 1), (('MILK', 'TEA'), 1), (('COFFEE', 'TEA'), 1), (('CORNFLAKES', 'TEA'), 1), (('COFFEE', 'MILK'), 1), (('CORNFLAKES', 'MILK'), 1), (('COFFEE', 'CORNFLAKES'), 1)]\n"
     ]
    }
   ],
   "source": [
    "print( \"flattened C2T: \", rddC2TFlat.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1229f9d",
   "metadata": {},
   "source": [
    "### **Phase 3**: Compute 𝐿2 from 𝐶2(𝑇)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3c2530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('BREAD', 'MILK'), 4)\n",
      "(('BISCUIT', 'BREAD'), 4)\n",
      "(('BREAD', 'TEA'), 4)\n",
      "(('MAGGI', 'TEA'), 4)\n",
      "(('COFFEE', 'CORNFLAKES'), 4)\n",
      "(('COFFEE', 'SUGER'), 4)\n",
      "(('BREAD', 'SUGER'), 4)\n",
      "(('BISCUIT', 'CORNFLAKES'), 3)\n",
      "(('BREAD', 'MAGGI'), 3)\n",
      "(('COCK', 'COFFEE'), 3)\n",
      "(('BREAD', 'COFFEE'), 3)\n",
      "(('BOURNVITA', 'BREAD'), 3)\n",
      "(('BISCUIT', 'MILK'), 2)\n",
      "(('CORNFLAKES', 'MILK'), 2)\n",
      "(('BISCUIT', 'MAGGI'), 2)\n",
      "(('BISCUIT', 'TEA'), 2)\n",
      "(('CORNFLAKES', 'TEA'), 2)\n",
      "(('BISCUIT', 'COFFEE'), 2)\n",
      "(('BISCUIT', 'COCK'), 2)\n",
      "(('COCK', 'CORNFLAKES'), 2)\n",
      "(('BOURNVITA', 'TEA'), 2)\n",
      "(('JAM', 'MAGGI'), 2)\n",
      "(('BREAD', 'JAM'), 2)\n",
      "(('BOURNVITA', 'SUGER'), 2)\n",
      "(('BREAD', 'CORNFLAKES'), 1)\n",
      "(('MAGGI', 'MILK'), 1)\n",
      "(('CORNFLAKES', 'MAGGI'), 1)\n",
      "(('BREAD', 'COCK'), 1)\n",
      "(('BISCUIT', 'SUGER'), 1)\n",
      "(('CORNFLAKES', 'SUGER'), 1)\n",
      "(('MILK', 'TEA'), 1)\n",
      "(('COFFEE', 'TEA'), 1)\n",
      "(('COFFEE', 'MILK'), 1)\n",
      "(('JAM', 'MILK'), 1)\n",
      "(('JAM', 'TEA'), 1)\n",
      "(('BOURNVITA', 'COFFEE'), 1)\n"
     ]
    }
   ],
   "source": [
    "def computeL2( rddC2T, numtrans, theta ):\n",
    "    pairsCountedrdd = rddC2T.reduceByKey( lambda v1,v2 : v1+v2 )\n",
    "    # Finally, filter out from the previous rdd those pairs with frequency below theta\n",
    "    return pairsCountedrdd.filter( lambda x : (float(x[1])/numtrans) >= theta )\n",
    "\n",
    "rddL2 = computeL2( rddC2TFlat, number_transactions, theta )\n",
    "\n",
    "rddL2 = rddL2.sortBy(lambda a: -a[1])\n",
    "for it in rddL2.toLocalIterator():\n",
    "    print (it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9a8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
